{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f73480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsidiag as gd\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb30182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0806f6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020010100', '2020010106']\n"
     ]
    }
   ],
   "source": [
    "DIRdiag = \"/home/patrick/readDiag/data\"\n",
    "\n",
    "varName = \"amsua\"\n",
    "varType = \"n15\"\n",
    "dateIni=\"2020010100\" \n",
    "dateFin=\"2020010106\" \n",
    "nHour = \"6\"          \n",
    "vminOMA = -2.0       \n",
    "vmaxOMA = 2.0        \n",
    "vminSTD = 0.0        \n",
    "vmaxSTD = 14.0       \n",
    "Level = 1000\n",
    "Lay = None           \n",
    "SingleL = \"All\" \n",
    "\n",
    "datei = datetime.strptime(str(dateIni), \"%Y%m%d%H\")\n",
    "datef = datetime.strptime(str(dateFin), \"%Y%m%d%H\")\n",
    "dates = [dates.strftime('%Y%m%d%H') for dates in pd.date_range(datei, datef,freq=\"6H\").tolist()]\n",
    "\n",
    "print(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c313c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/patrick/readDiag/data/2020010100/diag_amsua_n15_01.2020010100', '/home/patrick/readDiag/data/2020010106/diag_amsua_n15_01.2020010106']\n",
      "\n",
      "['/home/patrick/readDiag/data/2020010100/diag_amsua_n15_03.2020010100', '/home/patrick/readDiag/data/2020010106/diag_amsua_n15_03.2020010106']\n"
     ]
    }
   ],
   "source": [
    "paths, pathsc = [], []\n",
    "\n",
    "OuterL = \"01\"        \n",
    "[paths.append(DIRdiag+\"/\"+dt+\"/diag_amsua_n15_\"+OuterL+\".\"+dt) for dt in dates]\n",
    "\n",
    "OuterLc = \"03\"\n",
    "[pathsc.append(DIRdiag+\"/\"+dt+\"/diag_amsua_n15_\"+OuterLc+\".\"+dt) for dt in dates]\n",
    "\n",
    "print(paths)\n",
    "print(\"\")\n",
    "print(pathsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9981ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aguarde, o tempo total estimado para a leitura dos arquivos é de 0 minutos e 40 segundos.\n",
      "\n",
      "Reading /home/patrick/readDiag/data/2020010100/diag_amsua_n15_01.2020010100\n",
      " \n",
      ">>> GSI DIAG <<<\n",
      " \n",
      "Reading /home/patrick/readDiag/data/2020010106/diag_amsua_n15_01.2020010106\n",
      " \n",
      ">>> GSI DIAG <<<\n",
      " \n",
      "[<gsidiag.__main__.read_diag object at 0x7f3da297bc50>, <gsidiag.__main__.read_diag object at 0x7f3da97a6a50>]\n",
      "Mean Squared Error: 0.021331442520022392\n",
      "Dados salvos no arquivo /home/patrick/readDiag/data/2020010100/diag_amsua_n15_01.2020010100.csv\n",
      "Mean Squared Error: 0.019207065925002098\n",
      "Dados salvos no arquivo /home/patrick/readDiag/data/2020010106/diag_amsua_n15_01.2020010106.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "read = True\n",
    "\n",
    "if read:        \n",
    "    gdf_list = []\n",
    "    print(\"\")\n",
    "    print(\"Aguarde, o tempo total estimado para a leitura dos arquivos é de \"+\n",
    "          str(int((float(len(paths))*20 )/60))+\" minutos e \"+\n",
    "          str(int((float(len(paths))*20 )%60))+\" segundos.\")\n",
    "    print(\"\")\n",
    "    for path, pathc in zip(paths,pathsc):\n",
    "        print(\"Reading \"+path)\n",
    "        gdf = gd.read_diag(path,pathc)\n",
    "        gdf_list.append(gdf)\n",
    "\n",
    "    print(gdf_list)\n",
    "    \n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    \n",
    "\n",
    "    organizar_campos = ['lat','lon','elev','nchan','time','iuse','idqc','inverr','oer','obs',\n",
    "                     'omf','omf_nobc','emiss','oma','oma_nobc','imp','dfs']\n",
    "    \n",
    "    \n",
    "    for objeto in gdf_list:\n",
    "        \n",
    "        nome_arquivo_csv = str(objeto._diagFile) + \".csv\"\n",
    "\n",
    "        with open(nome_arquivo_csv, mode='w', newline='') as arquivo_csv:\n",
    "\n",
    "            escritor_csv = csv.DictWriter(arquivo_csv, fieldnames=organizar_campos)\n",
    "        \n",
    "            dados = []\n",
    "\n",
    "            dados_dict = {\n",
    "                'lat': objeto.obsInfo[varName].loc[varType].lat,\n",
    "                'lon': objeto.obsInfo[varName].loc[varType].lon,\n",
    "                'elev': objeto.obsInfo[varName].loc[varType].elev,\n",
    "                'nchan': objeto.obsInfo[varName].loc[varType].nchan,\n",
    "                'time': objeto.obsInfo[varName].loc[varType].time,\n",
    "                'iuse': objeto.obsInfo[varName].loc[varType].iuse,\n",
    "                'idqc': objeto.obsInfo[varName].loc[varType].idqc,\n",
    "                'inverr': objeto.obsInfo[varName].loc[varType].inverr,\n",
    "                'oer': objeto.obsInfo[varName].loc[varType].oer,\n",
    "                'obs': objeto.obsInfo[varName].loc[varType].obs,\n",
    "                'omf': objeto.obsInfo[varName].loc[varType].omf,\n",
    "                'omf_nobc': objeto.obsInfo[varName].loc[varType].omf_nobc,\n",
    "                'emiss': objeto.obsInfo[varName].loc[varType].emiss,\n",
    "                'oma': objeto.obsInfo[varName].loc[varType].oma,\n",
    "                'oma_nobc': objeto.obsInfo[varName].loc[varType].oma_nobc,\n",
    "                'imp': objeto.obsInfo[varName].loc[varType].imp,\n",
    "                'dfs': objeto.obsInfo[varName].loc[varType].dfs\n",
    "                }\n",
    "\n",
    "            dados.append(dados_dict)\n",
    "            \n",
    "            df = pd.DataFrame(dados_dict)\n",
    "            \n",
    "            pd.set_option('display.width', None)\n",
    "            \n",
    "            df.to_csv(arquivo_csv, index=True)\n",
    "                \n",
    "            arquivo_csv.close()   \n",
    "            \n",
    "            \n",
    "            df = df.dropna()\n",
    "            \n",
    "            # Separar as variáveis independentes (X) e o target (y)\n",
    "            X = df.drop('imp', axis=1)\n",
    "            y = df['imp']\n",
    "\n",
    "            # Dividir os dados em conjunto de treinamento e teste\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            df = df.dropna()\n",
    "            \n",
    "            \n",
    "            # Inicializar e treinar um modelo de regressão linear\n",
    "            modelo = LinearRegression()\n",
    "            modelo.fit(X_train, y_train)\n",
    "\n",
    "            # Fazer previsões no conjunto de teste\n",
    "            previsoes = modelo.predict(X_test)\n",
    "\n",
    "            # Avaliar o desempenho do modelo\n",
    "            mse = mean_squared_error(y_test, previsoes)\n",
    "            print(f'Mean Squared Error: {mse}')\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(f'Dados salvos no arquivo {nome_arquivo_csv}')\n",
    "        \n",
    "    print(\"Done!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd9ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
