{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdc562f",
   "metadata": {},
   "source": [
    "# Introdução ao Machine Learning\n",
    "\n",
    "O **Machine Learning (ML)**, ou **Aprendizado de Máquina**, é uma disciplina da inteligência artificial que se concentra no desenvolvimento de algoritmos e modelos que permitem que sistemas computacionais aprendam padrões e façam previsões a partir de dados, sem serem explicitamente programados para tarefas específicas. Em vez disso, os modelos de machine learning são treinados usando dados históricos e exemplos para aprender a realizar uma determinada tarefa ou fazer uma predição.\n",
    "\n",
    "# Tipos de Aprendizado de Máquina\n",
    "\n",
    "Existem três tipos principais de aprendizado de máquina:\n",
    "\n",
    "**Aprendizado Supervisionado:** Neste tipo de aprendizado, os modelos são treinados em um conjunto de dados rotulados, onde cada exemplo de entrada é associado a uma saída desejada. O objetivo é aprender a mapear as entradas para as saídas corretas, de modo que o modelo possa fazer previsões precisas em novos dados não rotulados.\n",
    "\n",
    "**Aprendizado Não Supervisionado:** Aqui, os modelos são treinados em conjuntos de dados não rotulados, e o objetivo é encontrar padrões ou estruturas nos dados sem a necessidade de rótulos pré-existentes. O aprendizado não supervisionado é frequentemente usado para tarefas como clusterização, redução de dimensionalidade e análise de associação.\n",
    "\n",
    "**Aprendizado por Reforço:** Neste paradigma, os modelos aprendem através da interação com um ambiente dinâmico, recebendo feedback na forma de recompensas ou penalidades. O objetivo é que o modelo aprenda a tomar ações que maximizem a recompensa ao longo do tempo, aprendendo assim uma política ou estratégia ótima.\n",
    "\n",
    "# Componentes do Processo de Machine Learning\n",
    "\n",
    "O processo de machine learning geralmente envolve os seguintes componentes:\n",
    "\n",
    "**Coleta e Preparação de Dados:** Esta fase envolve a coleta de dados relevantes para a tarefa em questão e o processamento desses dados para garantir que estejam limpos, completos e prontos para serem usados no treinamento do modelo.\n",
    "\n",
    "**Seleção e Engenharia de Recursos:** Aqui, os atributos ou características dos dados são selecionados e, se necessário, transformados ou criados para melhor representar as informações relevantes para o modelo.\n",
    "\n",
    "**Escolha do Algoritmo de Machine Learning:** Com base no tipo de problema e nos requisitos específicos, um algoritmo de machine learning adequado é escolhido para treinar o modelo.\n",
    "\n",
    "**Treinamento do Modelo:** Nesta etapa, o modelo é alimentado com os dados de treinamento para aprender a relação entre as entradas e as saídas desejadas. Isso envolve ajustar os parâmetros do modelo para minimizar uma função de perda ou maximizar uma função de recompensa.\n",
    "\n",
    "**Avaliação do Modelo:** Após o treinamento, o modelo é avaliado usando um conjunto de dados de validação ou teste para verificar seu desempenho e generalização em dados não vistos.\n",
    "\n",
    "**Ajuste de Hiperparâmetros:** Se necessário, os hiperparâmetros do modelo são ajustados para otimizar o desempenho do modelo em novos dados.\n",
    "\n",
    "**Implantação e Monitoramento:** Finalmente, o modelo treinado é implantado em um ambiente de produção e monitorado continuamente para garantir que ele mantenha seu desempenho e eficácia ao longo do tempo.\n",
    "\n",
    "# Aplicações do Machine Learning\n",
    "\n",
    "O Machine Learning tem uma ampla gama de aplicações em várias indústrias e domínios, incluindo:\n",
    "\n",
    "**Finanças:** Detecção de fraudes, previsão de riscos, análise de crédito.\n",
    "\n",
    "**Saúde:** Diagnóstico médico, descoberta de medicamentos, análise de imagens médicas.\n",
    "\n",
    "**Varejo:** Recomendação de produtos, previsão de demanda, detecção de anomalias.\n",
    "\n",
    "**Tecnologia:** Reconhecimento de voz, tradução automática, veículos autônomos.\n",
    "\n",
    "**Marketing:** Segmentação de clientes, personalização de conteúdo, otimização de campanhas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612a99f",
   "metadata": {},
   "source": [
    "# Script tutorial - XGBoost (Extreme Gradient Boosting)\n",
    "\n",
    "## Gradient Boosting\n",
    "\n",
    "O XGBoost é uma implementação do algoritmo de Gradient Boosting, que é uma técnica de ensemble learning. O Gradient Boosting funciona construindo modelos de aprendizado de máquina sequencialmente, onde cada modelo tenta corrigir os erros do modelo anterior. Em cada iteração, o modelo é treinado para prever a diferença entre as previsões atuais e os valores reais (gradiente), e o próximo modelo é treinado para prever essas diferenças.\n",
    "\n",
    "## Árvores de Decisão\n",
    "\n",
    "No XGBoost, os modelos base são geralmente árvores de decisão. Uma árvore de decisão é uma estrutura hierárquica de nós que representam decisões e suas possíveis consequências. Cada nó na árvore representa uma característica do conjunto de dados e cada ramo representa uma possível resposta a essa característica. A árvore é construída de forma iterativa, dividindo os dados em subconjuntos cada vez mais puros até que um critério de parada seja alcançado.\n",
    "\n",
    "## Gradient Boosting Trees\n",
    "\n",
    "O XGBoost constrói modelos de Gradient Boosting Trees, onde cada modelo é uma combinação linear de várias árvores de decisão fracas. Cada árvore é treinada para prever os resíduos do modelo anterior, ou seja, a diferença entre as previsões atuais e os valores reais. As árvores são adicionadas sequencialmente ao modelo, cada uma tentando corrigir os erros das árvores anteriores.\n",
    "\n",
    "## Principais Características do XGBoost\n",
    "\n",
    "### Regularização\n",
    "\n",
    "O XGBoost utiliza técnicas de regularização para evitar overfitting e melhorar a generalização do modelo. Isso inclui penalidades nos pesos das árvores e a limitação da complexidade das árvores para evitar o crescimento excessivo.\n",
    "\n",
    "### Funcionalidades de Split\n",
    "\n",
    "O XGBoost utiliza uma abordagem eficiente para encontrar os pontos de divisão ideais durante a construção das árvores de decisão. Ele considera várias medidas de impureza, como ganho de informação e ganho de Gini, e utiliza algoritmos de otimização eficientes para encontrar as divisões que maximizam essas medidas.\n",
    "\n",
    "### Processamento Paralelo\n",
    "\n",
    "Uma das principais vantagens do XGBoost é sua capacidade de processamento paralelo e distribuído. Ele pode aproveitar eficientemente o poder de computação de hardware moderno, como CPUs multi-core e GPUs, para acelerar o treinamento e a inferência dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c777bf",
   "metadata": {},
   "source": [
    "<img src=\"XGB.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6bf03",
   "metadata": {},
   "source": [
    "# Funcionamento do Script utilizando XGBoost para Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06745f2d",
   "metadata": {},
   "source": [
    "**1 - Importação de Bibliotecas:** O script começa importando as bibliotecas necessárias, incluindo pandas para manipulação de dados, scikit-learn para construção do modelo de XGBoost e métricas de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d645d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc2818",
   "metadata": {},
   "source": [
    "**2 - Carregamento dos Dados:** Em seguida, o script carrega os dados do arquivo de texto \"DadosBancarios.txt\" utilizando a função 'pd.read_csv()'. Esta etapa é crucial para preparar os dados para treinamento e teste do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados do arquivo txt\n",
    "dados = pd.read_csv('DadosBancarios.txt', sep=',')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b0177",
   "metadata": {},
   "source": [
    "**3 - Visualização dos Dados:** O script exibe os primeiros registros do conjunto de dados carregados usando 'print(dados.head())'. Isso permite uma rápida inspeção dos dados para garantir que foram carregados corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ec9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os primeiros registros do conjunto de dados\n",
    "print(\"Visualização dos primeiros registros do conjunto de dados:\")\n",
    "print(dados.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24637d03",
   "metadata": {},
   "source": [
    "**4 - Preparação dos Dados:** \n",
    "    \n",
    "    'LabelEncoder()': Este é um objeto da classe LabelEncoder do scikit-learn, que é usada para codificar variáveis categóricas em números inteiros.\n",
    "    \n",
    "    O método fit_transform()' ajusta o LabelEncoder ao conjunto de dados e, em seguida, transforma os valores da coluna 'EstadoCivil' de strings em números inteiros.\n",
    "    \n",
    "    O conjunto de dados é dividido em features (X) e target (y), onde as features são todas as colunas, exceto a coluna \"Aprovado\", que é nossa variável alvo. Isso é feito usando o método 'drop()' do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificação de rótulos para variável categórica \"Aprovado\"\n",
    "le = LabelEncoder()\n",
    "dados['Aprovado'] = le.fit_transform(dados['Aprovado'])\n",
    "\n",
    "# Codificação de rótulos para variável categórica \"cartao de credito\"\n",
    "dados['CartaoCredito'] = le.fit_transform(dados['CartaoCredito'])\n",
    "\n",
    "# Codificação de rótulos para variável categórica \"EstadoCivil\"\n",
    "dados['EstadoCivil'] = le.fit_transform(dados['EstadoCivil'])\n",
    "\n",
    "# Separando as features (atributos) e o target (variável que queremos prever)\n",
    "X = dados.drop('Emprestimo', axis=1)  # Features\n",
    "y = dados['Emprestimo']  # Target\n",
    "\n",
    "print(\"X = \\n\", X.head())\n",
    "print(\"\\nY = \\n\", y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969b7ed",
   "metadata": {},
   "source": [
    "**5 - Divisão em Conjuntos de Treinamento e Teste:** Os dados são divididos em conjuntos de treinamento e teste usando a função 'train_test_split()' do scikit-learn. Isso permite avaliar a capacidade do modelo de generalizar para novos dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd73722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o conjunto de dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Conjunto de treinamento: \\n\")\n",
    "print(\"\\nX_train = \\n\", X_train.head())\n",
    "print(\"\\nY_train = \\n\", y_train.head())\n",
    "print(\"\\nConjunto de teste: \\n\")\n",
    "print(\"\\nX_test = \\n\", X_test.head())\n",
    "print(\"\\nY_test = \\n\", y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7720a",
   "metadata": {},
   "source": [
    "**6 - Construção e Treinamento do Modelo:** O script cria um classificador de usando 'XGBRegressor()' do xgb. Este classificador é treinado com os dados de treinamento usando o método 'fit()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d60e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o regressor XGBoost\n",
    "xgb_regressor = XGBRegressor()\n",
    "\n",
    "# Treinando o modelo\n",
    "xgb_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103ba98",
   "metadata": {},
   "source": [
    "**7 - Avaliação do Modelo:** Após o treinamento, o modelo é avaliado usando os dados de teste. As previsões são feitas para os dados de teste usando predict() e o erro médio quadrático do modelo é calculada usando mean_squared_error() do scikit-learn.\n",
    "    \n",
    "**Exibição do erro médio quadrático (MSE) e a raiz o erro médio quadrático (RMSE):** Por fim, o script imprime o erro médio quadrático (MSE) e sua raiz (RMSE) do modelo, que é uma medida da precisão das previsões do modelo em relação aos rótulos verdadeiros dos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "print(\"Previsões do modelo para o conjunto de teste: \")\n",
    "print(y_pred)\n",
    "\n",
    "print(\"\\nConjunto de teste (y_test):\")\n",
    "print(y_test)\n",
    "\n",
    "# Calculando o erro médio quadrático (MSE) do modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"\\nErro médio quadrático do modelo:\", mse)\n",
    "\n",
    "# Calculando o RMSE do modelo\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"\\nRMSE do modelo:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab894f3",
   "metadata": {},
   "source": [
    "**Créditos:**\n",
    "- Patrick dos Santos Câmara\n",
    "- ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e05e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readDiag",
   "language": "python",
   "name": "readdiag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
