{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e810b25",
   "metadata": {},
   "source": [
    "Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f73480",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gsidiag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_208062/3240260457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgsidiag\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gsidiag'"
     ]
    }
   ],
   "source": [
    "import gsidiag as gd\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb30182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357b191",
   "metadata": {},
   "source": [
    "Definindo parâmetros para o uso do readDiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRdiag = \"/home/patrick/readDiag/data\"\n",
    "\n",
    "varName = \"amsua\"\n",
    "varType = \"n15\"\n",
    "dateIni=\"2020010100\" \n",
    "dateFin=\"2020010106\" \n",
    "nHour = \"6\"          \n",
    "vminOMA = -2.0       \n",
    "vmaxOMA = 2.0        \n",
    "vminSTD = 0.0        \n",
    "vmaxSTD = 14.0       \n",
    "Level = 1000\n",
    "Lay = None           \n",
    "SingleL = \"All\" \n",
    "\n",
    "datei = datetime.strptime(str(dateIni), \"%Y%m%d%H\")\n",
    "datef = datetime.strptime(str(dateFin), \"%Y%m%d%H\")\n",
    "dates = [dates.strftime('%Y%m%d%H') for dates in pd.date_range(datei, datef,freq=\"6H\").tolist()]\n",
    "\n",
    "print(dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d45849",
   "metadata": {},
   "source": [
    "Encontrando e listando arquivos para serem usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, pathsc = [], []\n",
    "\n",
    "OuterL = \"01\"        \n",
    "[paths.append(DIRdiag+\"/\"+dt+\"/diag_amsua_n15_\"+OuterL+\".\"+dt) for dt in dates]\n",
    "\n",
    "OuterLc = \"03\"\n",
    "[pathsc.append(DIRdiag+\"/\"+dt+\"/diag_amsua_n15_\"+OuterLc+\".\"+dt) for dt in dates]\n",
    "\n",
    "print(paths)\n",
    "print(\"\")\n",
    "print(pathsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771b1b8",
   "metadata": {},
   "source": [
    "Lendo arquivos listado usando o readDiag, concatenando os dados e fazendo primeira separação de dados para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9981ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "read = True\n",
    "\n",
    "if read:        \n",
    "    gdf_list = []\n",
    "    print(\"\")\n",
    "    print(\"Aguarde, o tempo total estimado para a leitura dos arquivos é de \"+\n",
    "          str(int((float(len(paths))*20 )/60))+\" minutos e \"+\n",
    "          str(int((float(len(paths))*20 )%60))+\" segundos.\")\n",
    "    print(\"\")\n",
    "    for path, pathc in zip(paths,pathsc):\n",
    "        print(\"Reading \"+path)\n",
    "        gdf = gd.read_diag(path,pathc)\n",
    "        gdf_list.append(gdf)\n",
    "\n",
    "    print(gdf_list)\n",
    "    \n",
    "    separator = \" =====================================================================================================\"\n",
    "\n",
    "    df_concatenado = pd.DataFrame()\n",
    "    \n",
    "    for objeto in gdf_list:\n",
    "        \n",
    "        print(separator)\n",
    "        print(\"Separando dados do arquivo\" + str(objeto._diagFile))\n",
    "        print(separator)\n",
    "        \n",
    "        \n",
    "        dados_dict = {\n",
    "                'lat': objeto.obsInfo[varName].loc[varType].lat,\n",
    "                'lon': objeto.obsInfo[varName].loc[varType].lon,\n",
    "                'elev': objeto.obsInfo[varName].loc[varType].elev,\n",
    "                'nchan': objeto.obsInfo[varName].loc[varType].nchan,\n",
    "                'time': objeto.obsInfo[varName].loc[varType].time,\n",
    "                'iuse': objeto.obsInfo[varName].loc[varType].iuse,\n",
    "                'idqc': objeto.obsInfo[varName].loc[varType].idqc,\n",
    "                'inverr': objeto.obsInfo[varName].loc[varType].inverr,\n",
    "                'oer': objeto.obsInfo[varName].loc[varType].oer,\n",
    "                'obs': objeto.obsInfo[varName].loc[varType].obs,\n",
    "                'omf': objeto.obsInfo[varName].loc[varType].omf,\n",
    "                'omf_nobc': objeto.obsInfo[varName].loc[varType].omf_nobc,\n",
    "                'emiss': objeto.obsInfo[varName].loc[varType].emiss,\n",
    "                'oma': objeto.obsInfo[varName].loc[varType].oma,\n",
    "                'oma_nobc': objeto.obsInfo[varName].loc[varType].oma_nobc,\n",
    "                'imp': objeto.obsInfo[varName].loc[varType].imp,\n",
    "                'dfs': objeto.obsInfo[varName].loc[varType].dfs\n",
    "                }\n",
    "        \n",
    "        df_objeto = pd.DataFrame(dados_dict)\n",
    "        \n",
    "        df_concatenado = pd.concat([df_concatenado, df_objeto], ignore_index=True)\n",
    "    \n",
    "    print(separator)\n",
    "    \n",
    "    df_concatenado.dropna(inplace=True)\n",
    "    \n",
    "    print(df_concatenado)\n",
    "    #canaisimp_df = canaisimp_df.loc[canais_df.index]\n",
    "    \n",
    "    #print(canais_df)\n",
    "    #print(canaisimp_df)\n",
    "    \n",
    "    print(separator)\n",
    "    \n",
    "    atributos = ['nchan', 'omf', 'oma', 'dfs']\n",
    "    \n",
    "    X = df_concatenado[atributos]\n",
    "    y = df_concatenado['imp']\n",
    "    \n",
    "    # Dividir os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print('Treino e Teste prontos')\n",
    "    print(separator)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4a2b5",
   "metadata": {},
   "source": [
    "Treinamento completo do primeiro modelo de IA: Floresta Aleatória para Regressão (dados contínuos), e plotando resultados estatísticos do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c4bebe",
   "metadata": {},
   "source": [
    "Definição da função para discretizar os dados de impacto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que retorna a categoria:\n",
    "def categoria_de(valorRF):\n",
    "    categoria = None\n",
    "    if valorRF <= -0.25:\n",
    "        categoria = \"Impacto negativo alto\"\n",
    "    elif valorRF > -0.25 and valorRF < 0:\n",
    "        categoria = \"Impacto negativo baixo\"\n",
    "    elif valorRF == 0:\n",
    "        categoria = \"Impacto neutro\"\n",
    "    elif valorRF > 0 and valorRF < 0.25:\n",
    "        categoria = \"Impacto positivo baixo\"\n",
    "    elif valorRF >= 0.25:\n",
    "        categoria = \"Impacto positivo alto\"\n",
    "    return categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a70ef",
   "metadata": {},
   "source": [
    "Segunda leitura dos arquivos, concatenando os dados e aplicando a função para discretizar os dados de impacto, ao final, os dados são separados para treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33337787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenado2 = pd.DataFrame()\n",
    "\n",
    "for objeto in gdf_list:\n",
    "        \n",
    "    print(separator)\n",
    "    print(\"Separando dados do arquivo\" + str(objeto._diagFile))\n",
    "    print(separator)\n",
    "        \n",
    "        \n",
    "    dados_dict = {\n",
    "            'lat': objeto.obsInfo[varName].loc[varType].lat,\n",
    "            'lon': objeto.obsInfo[varName].loc[varType].lon,\n",
    "            'elev': objeto.obsInfo[varName].loc[varType].elev,\n",
    "            'nchan': objeto.obsInfo[varName].loc[varType].nchan,\n",
    "            'time': objeto.obsInfo[varName].loc[varType].time,\n",
    "            'iuse': objeto.obsInfo[varName].loc[varType].iuse,\n",
    "            'idqc': objeto.obsInfo[varName].loc[varType].idqc,\n",
    "            'inverr': objeto.obsInfo[varName].loc[varType].inverr,\n",
    "            'oer': objeto.obsInfo[varName].loc[varType].oer,\n",
    "            'obs': objeto.obsInfo[varName].loc[varType].obs,\n",
    "            'omf': objeto.obsInfo[varName].loc[varType].omf,\n",
    "            'omf_nobc': objeto.obsInfo[varName].loc[varType].omf_nobc,\n",
    "            'emiss': objeto.obsInfo[varName].loc[varType].emiss,\n",
    "            'oma': objeto.obsInfo[varName].loc[varType].oma,\n",
    "            'oma_nobc': objeto.obsInfo[varName].loc[varType].oma_nobc,\n",
    "            'imp': objeto.obsInfo[varName].loc[varType].imp,\n",
    "            'dfs': objeto.obsInfo[varName].loc[varType].dfs\n",
    "            }\n",
    "        \n",
    "    df_objeto = pd.DataFrame(dados_dict)\n",
    "    \n",
    "    df_objeto['imp_categ'] = df_objeto['imp'].apply(categoria_de)\n",
    "        \n",
    "    df_concatenado2 = pd.concat([df_concatenado2, df_objeto], ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "print(separator)\n",
    "    \n",
    "df_concatenado2.dropna(inplace=True)\n",
    "    \n",
    "print(df_concatenado2)\n",
    "\n",
    "print(separator)\n",
    "    \n",
    "atributos = ['nchan', 'omf', 'oma', 'dfs']\n",
    "    \n",
    "X = df_concatenado2[atributos]\n",
    "y = df_concatenado2['imp_categ']\n",
    "    \n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "print('Treino e Teste prontos')\n",
    "print(separator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6686c",
   "metadata": {},
   "source": [
    "Treinamento completo do segundo modelo de IA: Classificador usando Floresta Aleatória. Há prints da matriz de confusão e do relatório de classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "modeloRFC = RandomForestClassifier()\n",
    "modeloRFC.fit(X_train, y_train)\n",
    "print('Modelo treinado!')\n",
    "print(separator)\n",
    "      \n",
    "# Fazer previsões\n",
    "y_pred = modeloRFC.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "matriz_confusao = confusion_matrix(y_test, y_pred)\n",
    "relatorio_classificacao = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(matriz_confusao)\n",
    "\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(relatorio_classificacao)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36473fd",
   "metadata": {},
   "source": [
    "Plotagem da matriz de confusão e importância dos recursos (atributos) para o modelo de classificação com árvore aleatória "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558dcb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as classes\n",
    "classes = [\"Impacto positivo alto\", \"Impacto positivo baixo\", \"Impacto negativo baixo\", \"Impacto negativo alto\"]\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"Matriz de Confusão - RFC - Todos canais\")\n",
    "plt.xlabel(\"Valor Previsto\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "plt.savefig(\"MatrizConfusao_All_Ch.png\", facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "importances = modeloRFC.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in modeloRFC.estimators_], axis=0)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=atributos)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Importâncias dos recursos usando MDI\")\n",
    "ax.set_ylabel(\"Diminuição média na impureza\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"FeatureImportance_All_Ch.png\", facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35cece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)\n",
    "\n",
    "y_score = modeloRFC.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "\n",
    "pair_list = list(combinations(np.unique(y), 2))\n",
    "print(pair_list)\n",
    "\n",
    "pair_scores = []\n",
    "mean_tpr = dict()\n",
    "\n",
    "for ix, (label_a, label_b) in enumerate(pair_list):\n",
    "    a_mask = y_test == label_a\n",
    "    b_mask = y_test == label_b\n",
    "    ab_mask = np.logical_or(a_mask, b_mask)\n",
    "\n",
    "    a_true = a_mask[ab_mask]\n",
    "    b_true = b_mask[ab_mask]\n",
    "\n",
    "    idx_a = np.flatnonzero(label_binarizer.classes_ == label_a)[0]\n",
    "\n",
    "    if label_b in label_binarizer.classes_:\n",
    "        idx_b = np.flatnonzero(label_binarizer.classes_ == label_b)[0]\n",
    "        # Continua o restante do seu código aqui\n",
    "    else:\n",
    "        print(f\"A classe {label_b} não está presente nos dados de teste.\")\n",
    "\n",
    "    fpr_a, tpr_a, _ = roc_curve(a_true, y_score[ab_mask, idx_a])\n",
    "    fpr_b, tpr_b, _ = roc_curve(b_true, y_score[ab_mask, idx_b])\n",
    "\n",
    "    # Calcular a faixa de valores de FPR observados nas curvas ROC\n",
    "    fpr_min = min(np.min(fpr_a), np.min(fpr_b))\n",
    "    fpr_max = max(np.max(fpr_a), np.max(fpr_b))\n",
    "    fpr_grid = np.linspace(fpr_min, fpr_max, 100)  # Ajuste o número de pontos conforme necessário\n",
    "    \n",
    "    mean_tpr[ix] = np.zeros_like(fpr_grid)\n",
    "    mean_tpr[ix] += np.interp(fpr_grid, fpr_a, tpr_a)\n",
    "    mean_tpr[ix] += np.interp(fpr_grid, fpr_b, tpr_b)\n",
    "    mean_tpr[ix] /= 2\n",
    "    mean_score = auc(fpr_grid, mean_tpr[ix])\n",
    "    pair_scores.append(mean_score)\n",
    "\n",
    "    # Obtenha os nomes das classes do LabelBinarizer\n",
    "    target_names = label_binarizer.classes_\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    plt.plot(\n",
    "        fpr_grid,\n",
    "        mean_tpr[ix],\n",
    "        label=f\"Média {label_a} vs {label_b} (AUC = {mean_score :.2f})\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        a_true,\n",
    "        y_score[ab_mask, idx_a],\n",
    "        ax=ax,\n",
    "        name=f\"{label_a} como classe positiva\",\n",
    "    )\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        b_true,\n",
    "        y_score[ab_mask, idx_b],\n",
    "        ax=ax,\n",
    "        name=f\"{label_b} como classe positiva\",\n",
    "    )\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Chance Level')\n",
    "    \n",
    "    ax.set(\n",
    "        xlabel=\"Taxa de falso positivo\",\n",
    "        ylabel=\"Taxa de verdade positiva\",\n",
    "        title=f\"{target_names[idx_a]} vs {label_b} curva ROC\",\n",
    "    )\n",
    "    \n",
    "    plt.savefig(f'{target_names[idx_a]} vs {label_b}_curvaROC.png', facecolor='white')\n",
    "\n",
    "print(f\"Macro-averaged One-vs-One ROC AUC score:\\n{np.average(pair_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4d58ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_concatenado2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_208062/1245881777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Supondo que 'df' seja o seu DataFrame e 'canal' seja a coluna que contém os canais de radiância\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcanais\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_concatenado2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nchan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Obtém a lista de canais únicos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanais\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_concatenado2' is not defined"
     ]
    }
   ],
   "source": [
    "# Define as classes\n",
    "classes = [\"Impacto positivo alto\", \"Impacto positivo baixo\", \"Impacto negativo baixo\", \"Impacto negativo alto\"]\n",
    "\n",
    "# Supondo que 'df' seja o seu DataFrame e 'canal' seja a coluna que contém os canais de radiância\n",
    "canais = df_concatenado2['nchan'].unique()  # Obtém a lista de canais únicos\n",
    "\n",
    "print(canais)\n",
    "\n",
    "# Para cada canal, divida o DataFrame e treine um modelo\n",
    "\n",
    "atributos = ['omf', 'oma', 'dfs', 'oer', 'obs', 'oma_nobc', 'omf_nobc', 'lat', 'lon', 'emiss']\n",
    "\n",
    "modeloscanais = []\n",
    "resultados = []\n",
    "\n",
    "\n",
    "for canal in canais:\n",
    "    # Divida o DataFrame para o canal atual\n",
    "    df_canal = df_concatenado2[df_concatenado2['nchan'] == canal]\n",
    "    \n",
    "    # Verifique se a coluna 'canal' está presente\n",
    "    if 'nchan' in df_canal.columns:\n",
    "        # Separe os recursos (X) e o alvo (y)\n",
    "        \n",
    "        \n",
    "        X = df_canal[atributos]\n",
    "        y = df_canal['imp_categ']\n",
    "        \n",
    "        # Divida os dados em conjuntos de treinamento e teste\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Treine o modelo para o canal atual\n",
    "        nome_modelo = f\"modeloch{canal}\"\n",
    "        modeloch = RandomForestClassifier()\n",
    "        modeloscanais.append((nome_modelo, modeloch))\n",
    "        modeloch.fit(X_train, y_train)\n",
    "        \n",
    "        # Faça previsões\n",
    "        y_pred = modeloch.predict(X_test)\n",
    "        \n",
    "        # Avalie o modelo e imprima a matriz de confusão\n",
    "        matriz_confusao = confusion_matrix(y_test, y_pred)\n",
    "        print(f\"Matriz de Confusão para o canal {canal}:\")\n",
    "        #print(matriz_confusao)\n",
    "    else:\n",
    "        print(f\"Coluna 'canal' não encontrada para o canal {canal}. Verifique se os dados estão formatados corretamente.\")\n",
    "        \n",
    "    precisao_media = classification_report(y_test, y_pred, output_dict=True)['weighted avg']['precision']\n",
    "    resultados.append((canal, precisao_media))\n",
    "    \n",
    "    \n",
    "    # Plotar a matriz de confusão\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f\"Matriz de Confusão (RFC) do canal {canal}\")\n",
    "    plt.xlabel(\"Valor Previsto\")\n",
    "    plt.ylabel(\"Valor Real\")\n",
    "    plt.savefig(f\"MatrizConfusao_Channel_{canal}.png\", facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    importances = modeloch.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in modeloch.estimators_], axis=0)\n",
    "\n",
    "    forest_importances = pd.Series(importances, index=atributos)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(f\"Importâncias dos recursos usando MDI - Canal {canal}\")\n",
    "    ax.set_ylabel(\"Diminuição média na impureza\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"FeatureImportance_Channel_{canal}.png\", facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    relatorio_classificacao = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nRelatório de Classificação para o canal {canal}:\")\n",
    "    print(relatorio_classificacao)\n",
    "    \n",
    "resultados_ordenados = sorted(resultados, key=lambda x: x[1], reverse=True)\n",
    "for canal, precisao_media in resultados_ordenados:\n",
    "    print(f\"Modelo do canal: {canal}\")\n",
    "    print(f\"Precisão Média: {precisao_media}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecce286",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)\n",
    "\n",
    "y_score = modelo.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "display = RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    y_score[:, class_id],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    plot_chance_level=True,\n",
    ")\n",
    "_ = display.ax_.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\",\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Ajuste LabelBinarizer aos rótulos de treinamento\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "\n",
    "# Transforme os rótulos de teste em um formato binário\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "\n",
    "# Treine o modelo e obtenha as probabilidades das previsões\n",
    "y_score = modelo.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "# Obter as classes do LabelBinarizer\n",
    "classe = label_binarizer.classes_\n",
    "\n",
    "# Exibir as classes\n",
    "print(\"Classes presentes na lista:\")\n",
    "for c in classe:\n",
    "    print(c)\n",
    "\n",
    "# Escolha a classe de interesse e obtenha o índice correspondente\n",
    "class_of_interest = 'Impacto positivo baixo'  # substitua pela classe de interesse\n",
    "class_id = label_binarizer.classes_.tolist().index(class_of_interest)\n",
    "\n",
    "# Calcule a curva ROC para a classe de interesse\n",
    "fpr, tpr, _ = roc_curve(y_onehot_test[:, class_id], y_score[:, class_id])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Crie a exibição da curva ROC\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=f\"{class_of_interest} vs the rest\")\n",
    "\n",
    "# Plote a curva ROC\n",
    "display.plot()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('One-vs-Rest ROC curves')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12748d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = ['nchan', 'omf', 'oma', 'dfs']\n",
    "  \n",
    "print(df_concatenado2[atributos])\n",
    "print(df_concatenado2['imp_categ'])\n",
    "\n",
    "X = df_concatenado2[atributos]\n",
    "y = df_concatenado2['imp_categ']\n",
    "\n",
    "# Codificar os rótulos se necessário\n",
    "#label_encoder = LabelEncoder()\n",
    "#y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#X_train, X_test = X[:2000], X[2000:]\n",
    "#y_train, y_test = y[:2000], y[2000:]\n",
    "\n",
    "print('Gradiente Boosting Classifier')\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=5, random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Acurácia:\", score)\n",
    "\n",
    "matriz_confusao = confusion_matrix(y_test, y_pred)\n",
    "# Define as classes\n",
    "classes = [\"Impacto positivo alto\", \"Impacto positivo baixo\", \"Impacto negativo baixo\", \"Impacto negativo alto\"]\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"Matriz de Confusão - GBC - Todos canais\")\n",
    "plt.xlabel(\"Valor Previsto\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "plt.savefig(\"MatrizConfusao_All_Ch.png\", facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "clf.feature_importances_\n",
    "\n",
    "relatorio_classificacao = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nRelatório de Classificação:\")\n",
    "print(relatorio_classificacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = ['nchan', 'omf', 'oma', 'dfs']\n",
    "    \n",
    "X = df_concatenado2[atributos]\n",
    "y = df_concatenado2['imp_categ']\n",
    "\n",
    "\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "    voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a153e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "atributos = ['nchan', 'omf', 'oma', 'dfs']\n",
    "    \n",
    "X = df_concatenado2[atributos]\n",
    "y = df_concatenado2['imp_categ']\n",
    "\n",
    "modeloMLPC = MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "modeloMLPC.fit(X, y)\n",
    "\n",
    "y_pred = modeloMLPC.predict(X_test)\n",
    "\n",
    "score = modeloMLPC.score(X_test, y_test)\n",
    "print(\"Acurácia:\", score)\n",
    "\n",
    "matriz_confusao = confusion_matrix(y_test, y_pred)\n",
    "# Define as classes\n",
    "classes = [\"Impacto positivo alto\", \"Impacto positivo baixo\", \"Impacto negativo baixo\", \"Impacto negativo alto\"]\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"Matriz de Confusão - MLPC - Todos canais\")\n",
    "plt.xlabel(\"Valor Previsto\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "plt.savefig(\"MatrizConfusao_All_Ch.png\", facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "relatorio_classificacao = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nRelatório de Classificação:\")\n",
    "print(relatorio_classificacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Calcule os tamanhos de treinamento e as pontuações de treinamento/teste\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    modeloMLPC, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 100))\n",
    "\n",
    "# Calcule as médias e desvios padrão das pontuações de treinamento/teste\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Curva de Aprendizado (MLPClassifier)\")\n",
    "plt.xlabel(\"Tamanho do Conjunto de Treinamento\")\n",
    "plt.ylabel(\"Pontuação\")\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Pontuação de Treinamento\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Pontuação de Teste\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
